{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "from pso import PSO,Particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fitness(arr , x_train, y_train , x_validate , y_validate):\n",
    "    index = [i for i, e in enumerate(arr) if e == 1]\n",
    "    index = np.array(index)\n",
    "  \n",
    "    x_train_new = x_train.iloc[:,index] \n",
    "    print(x_train_new.shape)\n",
    "    x_val_new = x_validate.iloc[:,index]\n",
    "   \n",
    "    #regressor=Lasso(alpha=0.005,max_iter=100,normalize=False,tol=0.0005)\n",
    "    \n",
    "    #Lasso(alpha=1.0,max_iter=1000,normalize=False,tol=0.0001,fit_intercept=True,precompute=False,copy_X=True,warm_start=False,positive=False,random_state=None,selection='cyclic')\n",
    "    regressor=RandomForestRegressor(max_depth=80, max_features=3, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n",
    "    regressor.fit(x_train_new,y_train)\n",
    "    #DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=None,\n",
    "     #                   max_features=2, max_leaf_nodes=None,\n",
    "      #                  min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "       #                 min_samples_leaf=1, min_samples_split=2,\n",
    "        #                min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "         #               random_state=None, splitter='best')\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "## You van use any model (here provided 3 of them)\n",
    "    \n",
    "    \n",
    "    yp=regressor.predict(x_val_new)\n",
    "    mse = mean_squared_error(y_validate,yp)\n",
    "    Rmse=m.sqrt(mse)\n",
    "    AIC=('Enter the number of model samples')*m.log(Rmse)+2*len(index)\n",
    "    print(AIC)\n",
    "    return  AIC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read your dataset\n",
    "\n",
    "df=pd.read_excel('The name of your dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into train,validation and test\n",
    "\n",
    "train,validate,test=np.split(df.sample(frac=1),[int(.6*len(df)),int(.8*len(df))])\n",
    "# %60 for train, %20 for validation and %20 for test\n",
    "\n",
    "x_train=train.drop('The target feature',1)\n",
    "y_train=train.loc[:,'The target feature']\n",
    "x_test=test.drop('The target feature',1)\n",
    "y_test=test.loc[:,'The target feature']\n",
    "x_validate=validate.drop('The target feature',1)\n",
    "y_validate=validate.loc[:,'The target feature']\n",
    "\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the shape of test,train,validation and the whole dataset\n",
    "\n",
    "print('Training dataset shape:', x_train.shape, y_train.shape)\n",
    "print('Testing dataset shape:', x_test.shape, y_test.shape)\n",
    "print('Validation dataset shape:', x_validate.shape, y_validate.shape)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_dimentions = 80\n",
    "num_particles = 100\n",
    "maxiter = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call PSO\n",
    "pso = PSO(Fitness, x_train, y_train , x_validate , y_validate, problem_dimentions,num_particles,maxiter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run PSO\n",
    "best_solution, best_fitness = pso.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The selected features\n",
    "\n",
    "best_feature_selected = [i for i, e in enumerate(best_solution) if e == 1]\n",
    "x_train_new = x_train.iloc[:,best_feature_selected] \n",
    "\n",
    "x_train_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see how feature selection has helped us (1)\n",
    "\n",
    "regressor=RandomForestRegressor(max_depth=80, max_features=3, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n",
    "regressor.fit(x_train_new,y_train)\n",
    "\n",
    "\n",
    "x_test_new = x_test.iloc[:,best_feature_selected]\n",
    "print(x_test_new.shape)\n",
    "yp=regressor.predict(x_test_new)\n",
    "mse = mean_squared_error(y_test,yp)\n",
    "Rmse=m.sqrt(mse)\n",
    "AIC_1=('Enter the number of model samples')*m.log(Rmse)+2*len(x_train_new)\n",
    "print(AIC_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see how feature selection has helped us (2)\n",
    "\n",
    "regressor=RandomForestRegressor(max_depth=80, max_features=3, min_samples_leaf=5, min_samples_split=12, n_estimators=100)\n",
    "regressor.fit(x_train,y_train)\n",
    "\n",
    "\n",
    "print(x_test.shape)\n",
    "yp=regressor.predict(x_test)\n",
    "mse = mean_squared_error(y_test,yp)\n",
    "Rmse=m.sqrt(mse)\n",
    "AIC_2=('Enter the number of model samples')*m.log(Rmse)+2*len(x_train_new)\n",
    "print(AIC_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare AIC_1  and  AIC_2 !\n",
    "\n",
    "The less    AIC  is , The better it is ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
